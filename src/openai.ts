import { AxiosResponse } from "axios";
import { FileBox } from "file-box";
import fs from "fs";
import {
  ChatCompletionRequestMessage,
  Configuration,
  CreateChatCompletionResponse,
  CreateImageRequestResponseFormatEnum,
  CreateImageRequestSizeEnum,
  OpenAIApi
} from "openai";
import { Message } from "wechaty";
import { config } from "./config.js";
import DBUtils from "./data.js";
import { createEmotion, defaultEmotions } from "./function/emotion/register.js";
import { functionLoader } from "./function/funcloader.js";

import { FunctionMessageBuilder, FunctionResponse, MessageType, RuntimeDataCtx } from "./interface.js";


let cacheKeys: string[] = [];
let lastFetchTime = 0;
const cacheDuration = 2 * 60 * 60 * 1000; // ä¸¤ä¸ªå°æ—¶ï¼Œä»¥æ¯«ç§’ä¸ºå•ä½


let configuration = new Configuration({
  apiKey: config.openai_api_key,
  // apiKey: random(await keyProvider()),
  basePath: config.api,
});
const openai = new OpenAIApi(configuration);

/**
 * Get completion from OpenAI
 * @param username
 * @param message
 */
async function chatgpt(username: string, message: string): Promise<string> {
  // å…ˆå°†ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯æ·»åŠ åˆ°æ•°æ®åº“ä¸­
  DBUtils.addUserMessage(username, message);
  const messages = DBUtils.getChatMessage(username);
  const response = await catchManyRequstError(() => openai.createChatCompletion({
    model: config.model,
    messages: messages,
    temperature: config.temperature,
  }));
  let assistantMessage = "";
  try {
    if (response?.status === 200) {
      assistantMessage = response?.data.choices[0].message?.content?.replace(/^\n+|\n+$/g, "") as string;
    } else {
      console.log(`Something went wrong,Code: ${response?.status}, ${response?.statusText}`)
    }
  } catch (e: any) {
    if (e.request) {
      console.log("è¯·æ±‚å‡ºé”™");
    }
  }
  return assistantMessage;
}

/**
 * Get image from DallÂ·E
 * @param username
 * @param prompt
 */
async function dalle(username: string, prompt: string) {
  const response = await catchManyRequstError(() => openai.createImage({
    prompt: prompt,
    n: 1,
    size: CreateImageRequestSizeEnum._256x256,
    response_format: CreateImageRequestResponseFormatEnum.Url,
    user: username
  })).then((res) => res?.data).catch((err) => console.log(err));
  if (response) {
    return response.data[0].url;
  } else {
    return "Generate image failed"
  }
}

/**
 * Speech to text
 * @param username
 * @param videoPath
 */
async function whisper(username: string, message: Message): Promise<string> {
  const audioFileBox = await message.toFileBox();
  const api = await fetch('https://tosilk.zeabur.app/v1/decoder', {
    body: JSON.stringify({ base64: await audioFileBox.toBase64() }),
    method: 'post',
    headers: { "Content-Type": "application/json" }
  })
  const { data } = await api.json()
  const mp3 = FileBox.fromBase64(data, `${new Date().getTime()}.mp3`)
  await mp3.toFile(mp3.name)
  const file: any = fs.createReadStream(mp3.name);
  const response = await catchManyRequstError(() => openai.createTranscription(file, "whisper-1"))
    .then((res) => res?.data).catch((err) => console.log(err));
  fs.unlinkSync(mp3.name)
  if (response) {
    return response.text;
  } else {
    return "Speech to text failed"
  }
}


async function keyProvider(refresh: boolean = false) {
  const currentTime = new Date().getTime();
  // å¦‚æœç¼“å­˜ä¸ä¸ºç©ºä¸”åœ¨æœ‰æ•ˆæœŸå†…ï¼Œç›´æ¥è¿”å›ç¼“å­˜çš„ API å¯†é’¥
  if (cacheKeys.length > 0 && currentTime - lastFetchTime < cacheDuration && !refresh) {
    return cacheKeys;
  }

  // å¦åˆ™é‡æ–°è·å– API å¯†é’¥
  const url = `${config.openaiKeyUrl}?${currentTime}`;
  const api = await fetch(url, { method: 'get' })
  const res = await api.json();
  cacheKeys = res.APIkey.keys;
  lastFetchTime = currentTime;
  return cacheKeys;
}



async function getCompletion(messages: Array<ChatCompletionRequestMessage>, functionsSchema: Array<any>) {
  try {

    const response = await catchManyRequstError(() => openai.createChatCompletion({
      model: config.model,
      messages,
      functions: functionsSchema,
      temperature: 0,
    }));

    return response;
  } catch (error: any) {
    throw Error(`${error.response.statusText} ${error.response.data?.error?.message}`)
  }
};

/**
 * åˆ†ææ–‡å­—æƒ…ç»ªè¿”å›è¡¨æƒ…åŒ…
 * @param text æ–‡å­—
 * @returns è¡¨æƒ…åŒ…
 */
export async function assistantEmotion(text: string): Promise<any> {
  const [fn, _] = createEmotion()
  const response = await catchManyRequstError(() => openai.createChatCompletion({
    model: config.model,
    messages: [
      { role: "system", "content": `ç»™å®šæƒ…ç»ªç±»å‹ ${Object.keys(defaultEmotions)} åˆ†æç”¨æˆ·ç»™å‡ºçš„å¥å­çš„æƒ…ç»ª,æ— åŒ¹é…é¡¹åˆ™éšæœºå…¶ä¸­ä¸€ä¸ª ï¼Œä¸è¦åŠ ä»»ä½•è§£é‡Š` },
      { role: "user", content: text }
    ],
    temperature: 0,
  }));


  return FunctionMessageBuilder.build(await fn({ "text": response?.data.choices[0].message?.content || "æ— è¯­" }));
}

/**
 * chat with gpt functions
 * @param userId å½“å‰ç”¨æˆ·
 * @param message æ¶ˆæ¯
 * @returns ç»“æœ
 */
async function chatWithFunctions(userId: string, message: string): Promise<any> {

  // å…ˆå°†ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯æ·»åŠ åˆ°æ•°æ®åº“ä¸­
  DBUtils.addUserMessage(userId, message);
  const messages = DBUtils.getChatMessage(userId);

  // åŠ è½½è‡ªå®šä¹‰å‡½æ•°
  const { functions, functionsSchema } = functionLoader()
  console.log("Question: " + message);
  let response: AxiosResponse<CreateChatCompletionResponse, any> | undefined = await getCompletion(messages, functionsSchema);
  if (response && checkFinishReason(response)) {
    return functionCall(response, functionsSchema, functions, messages, userId)
  }

  return response?.data.choices[0].message?.content
}

/**
 * è°ƒç”¨å‡½æ•°
 * @param response openai å“åº”
 * @param functionsSchema è‡ªå®šä¹‰å‡½æ•°ç»“æ„
 * @param functions å‡½æ•°
 * @param messages å†å²æ¶ˆæ¯
 * @param username å½“å‰ç”¨æˆ·
 * @returns è°ƒç”¨ç»“æœ
 */
async function functionCall(response: AxiosResponse<CreateChatCompletionResponse, any> | undefined,
  functionsSchema: Array<any>,
  functions: any,
  messages: Array<ChatCompletionRequestMessage>,
  username: string): Promise<any> {

  try {
    const fnName = response?.data.choices[0].message?.function_call?.name || ""
    let args = response?.data.choices[0].message?.function_call?.arguments || "{}";
    // åœ¨è¿™é‡ŒåŠ ä¸Šæˆ‘ä»¬éœ€è¦çš„å…¶ä»–å‚æ•°ï¼Œä¾‹å¦‚ username
    const argsObj = { ...JSON.parse(args), username }
    args = JSON.stringify(argsObj)

    console.log("âš™ï¸ Function call: " + fnName);
    console.log(`ğŸ”¢ Arguments: `, argsObj);

    const fn = functions[fnName];
    const result: FunctionResponse = await fn(argsObj);

    if (result.save) {
      DBUtils.addRuntimeData(username, {
        name: "",
        data: result.data
      })
    }

    if (FunctionMessageBuilder.isDirectMsgType(result.msgType)) {
      const replyMessage = FunctionMessageBuilder.build(result)
      if (result.msgType === MessageType.ForwardMessage) {
        const bot = RuntimeDataCtx.get('bot')?.data
        await bot.puppet._client.api.forwardMessage(new Date().getTime(), username, result.data, 49, username);
        return "DONE!"
      } else {
        return replyMessage
      }
    }

    messages.push({
      role: "assistant",
      // @ts-ignore
      content: null,
      function_call: {
        name: fnName,
        arguments: args,
      },
    });

    messages.push({
      role: "function",
      name: fnName,
      content: JSON.stringify({ result: result.data }),
    });


    response = await getCompletion(messages, functionsSchema)
    if (response && checkFinishReason(response)) {
      return await functionCall(response, functionsSchema, functions, messages, username)
    }

    return response?.data.choices[0].message?.content || ""
  } catch (error: any) {
    return error.message
  }
}

/**
 * æ£€æŸ¥å®ŒæˆåŸå› 
 * @param response openai å“åº”
 * @param finish_reason é»˜è®¤ function_call
 * @returns bool
 */
function checkFinishReason(
  response: AxiosResponse<CreateChatCompletionResponse, any>,
  finish_reason: string = "function_call"
): boolean {
  return response && response.data.choices[0].finish_reason === finish_reason;
}


async function catchManyRequstError(request: () => Promise<AxiosResponse<any, any>>) {
  try {
    return await request()
  } catch (error: any) {
    // if (error.response.status == 429) {
    //   const apikey = random(await keyProvider(true))
    //   configuration = new Configuration({
    //     apiKey: apikey,
    //     basePath: config.api,
    //   });
    //   return await request()
    // }
    // TODO ...
    throw error
  }
}

export { chatgpt, dalle, whisper, keyProvider, chatWithFunctions };


